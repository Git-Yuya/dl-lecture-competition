# Configuration for training parameters
batch_size: 16       # Number of samples per gradient update
epochs: 10           # Number of complete passes through the training dataset
hid_dim: 512         # Hidden layer dimension
p_drop: 0.1          # Probability of dropout
lr: 0.001            # Learning rate for the optimizer
# weight_decay: 0.01  # Weight decay for the optimizer

# Device configuration
device: cuda:0       # Device to be used for computation (e.g., cuda:0 for the first GPU, or cpu for using the CPU)
num_workers: 4       # Number of subprocesses to use for data loading
seed: 1234           # Random seed for reproducibility
use_wandb: False     # Boolean flag to enable or disable Weights and Biases logging

# Data directory
data_dir: data       # Directory where the data is stored

# Evaluation configuration
model_path:          # Path to the model file for evaluation (leave blank if not used)
